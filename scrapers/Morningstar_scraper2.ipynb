{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "loose-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"morningstar_etf_data.pkl\", \"rb\") as f:\n",
    "    etf_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "suffering-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to https://www.morningstar.com/5-star-etfs and see how many pages there are on the site. Set num_pages\n",
    "# accordingly and the url accordingly and run. Repeat for all star etfs down to 1 star.\n",
    "\n",
    "num_pages = 2\n",
    "for i in range(1, num_pages+1):\n",
    "    url = \"https://www.morningstar.com/1-star-etfs?page={}\".format(i)\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers = headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    rows = soup.find_all(class_=\"mdc-table-row\")\n",
    "\n",
    "    for row in rows:\n",
    "        data_points = row.find_all(class_=\"mdc-data-point\")\n",
    "        data_points_list = []\n",
    "        for data_point in data_points:\n",
    "            data_points_list.append(data_point.text)\n",
    "        if len(data_points_list) != 8:\n",
    "            continue\n",
    "        name, ticker, morningstar_category, adjusted_expense_ratio, return_rank_in_category_1Y, return_rank_in_category_3Y, return_rank_in_category_5Y, active_or_passive = data_points_list\n",
    "        etf_data[ticker] = {\n",
    "            'name': name,\n",
    "            'morningstar_category': morningstar_category,\n",
    "            'adjusted_expense_ratio': adjusted_expense_ratio,\n",
    "            'return_rank_in_category_1Y': return_rank_in_category_1Y,\n",
    "            'return_rank_in_category_3Y': return_rank_in_category_3Y,\n",
    "            'return_rank_in_category_5Y': return_rank_in_category_5Y,\n",
    "            'active_or_passive': active_or_passive\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "suited-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"morningstar_etf_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(etf_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-legend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in etf_data:\n",
    "    url = \"https://query1.finance.yahoo.com/v7/finance/download/{}?period1=1370044800&period2=1685577600&interval=1d&events=history&includeAdjustedClose=true\".format(ticker)\n",
    "    response = requests.get(url, headers = headers)\n",
    "\n",
    "    save_path = \"Desktop/etf_historical_prices/{}.csv\".format(ticker)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    print(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "undefined-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_etf = {}\n",
    "\n",
    "spy = pd.read_csv(\"Desktop/etf_historical_prices/SPY.csv\")\n",
    "spy_movements = []\n",
    "for i in range(len(spy['Close']) - 1, 0, -1):\n",
    "    spy_movements.append(100*(spy['Close'][i]/spy['Close'][i-1] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in etf_data:\n",
    "    other = pd.read_csv(\"Desktop/etf_historical_prices/{}.csv\".format(ticker))\n",
    "    other_movements = []\n",
    "    for i in range(len(other['Close']) - 1, 0, -1):\n",
    "        other_movements.append(100*(other['Close'][i]/other['Close'][i-1] - 1))\n",
    "        \n",
    "    points = [0, 0, 0, 0]\n",
    "    \n",
    "    for i in range(len(other_movements)):\n",
    "        if spy_movements[i] > 0:\n",
    "            points[0] += other_movements[i] - spy_movements[i]\n",
    "        else:\n",
    "            points[1] += (other_movements[i] - spy_movements[i])*(abs(other_movements[i] - spy_movements[i]))\n",
    "        \n",
    "        if other_movements[i] > 0:\n",
    "            points[2] += other_movements[i] - spy_movements[i]\n",
    "        else:\n",
    "            points[3] += (other_movements[i] - spy_movements[i])*(abs(other_movements[i] - spy_movements[i]))\n",
    "    \n",
    "    points_per_etf[ticker] = points\n",
    "    print(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "convinced-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_funds = []\n",
    "\n",
    "for ticker in points_per_etf:\n",
    "    points = points_per_etf[ticker]\n",
    "    if points[0] >= 0 and points[0] + points[1] >= 0 and points[2] >= 0 and points[2] + points[3] >= 0:\n",
    "        fund = pd.read_csv(\"Desktop/etf_historical_prices/{}.csv\".format(ticker))\n",
    "        if len(fund) < 756:\n",
    "            continue\n",
    "        good_funds.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fund in good_funds:\n",
    "    print(fund, etf_data[fund]['name'], etf_data[fund]['morningstar_category'], etf_data[fund]['active_or_passive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "QTUM\n",
    "FTEC\n",
    "RYT\n",
    "IGM\n",
    "IXN\n",
    "TDV\n",
    "RGI\n",
    "FIW\n",
    "QQQ\n",
    "QQQE\n",
    "ONEQ\n",
    "VONG\n",
    "IWY\n",
    "NULG\n",
    "\n",
    "AVUS\n",
    "XLK\n",
    "VGT\n",
    "IYW\n",
    "QQEW\n",
    "IWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "treated-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[210.80707427103303,\n",
       " -156.75595237001983,\n",
       " 405.5905466775663,\n",
       " -305.1659680952048]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_per_etf['IXN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-soviet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
